{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3478ecf2-c74c-4dca-8285-823ced0821d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"gpjt/8xa100m40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd7c73e-e507-4491-9309-ce358ad3de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_source = \"gpjt/openassistant-guanaco-llama2-format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78bb383-59b9-478d-b0d4-677a0296f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82a5b07-1d9d-4c4c-bf56-8f101639cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9ef044-cff8-4178-aab2-ee8c8c9bb9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8852d213ac94636a2a0e956910d2959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/702M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522bedb5537f4ac4a9e7bd9216c99d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"cuda\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4dc2a9-705e-48d8-b46e-ab86a1585a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "{question} [/INST]\n",
    "{response}\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "def ask_question(model, question):\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)\n",
    "    prompt = prompt_template.format(question=question, response=\"\")\n",
    "    tokens_in = len(tokenizer(prompt)[\"input_ids\"])\n",
    "    start = time.time()\n",
    "    result = pipe(prompt)\n",
    "    end = time.time()\n",
    "    generated_text = result[0]['generated_text']\n",
    "    tokens_out = len(tokenizer(generated_text)[\"input_ids\"])\n",
    "    print(generated_text)\n",
    "    tokens_generated = tokens_out - tokens_in\n",
    "    time_taken = end - start\n",
    "    tokens_per_second = tokens_generated / time_taken\n",
    "    print(f\"{tokens_generated} tokens in {time_taken:.2f}s: {tokens_per_second:.2f} tokens/s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d954f60-b994-4395-8097-8dde854c5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Who is Leonardo Da Vinci? [/INST]\n",
      "\n",
      "\n",
      "Who is Leonardo Da Vinci?\n",
      "Who is Leonardo Da Vinci? [INST]command\n",
      "Who is Leonardo Da Vinci? [INST]command\n",
      "Who is Leonardo Da Vinci?\n",
      "Who is Leonardo Da Vinci?\n",
      "How do you know the answer to the question?\n",
      "What is Leonardo Da Vinci?\n",
      "Who is Leonardo Da Vinci?\n",
      "What is Leonardo Da Vinci?\n",
      "Who is Leonardo Da Vinci?\n",
      "Who is Leonardo Da Vinci?\n",
      "\n",
      "100 tokens in 0.74s: 134.69 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "ask_question(model, \"Who is Leonardo Da Vinci?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2194ba-1ba5-436e-b8fd-f82d415cac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528caf4941974b519d49f92d76969e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d4f88b2500482989e8618aad811c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"][:]\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5434c7-f9ed-4a21-9cbc-0889f3005fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "\n",
    "batch_size = 6\n",
    "args = TrainingArguments(\n",
    "    'outputs', \n",
    "    learning_rate=8e-5, \n",
    "    warmup_ratio=0.1, \n",
    "    lr_scheduler_type='cosine', \n",
    "    fp16=True,\n",
    "    eval_strategy=\"epoch\", \n",
    "    eval_on_start=True,\n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    num_train_epochs=6, \n",
    "    weight_decay=0.01, \n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b26e2c2-cdfd-404a-8644-cc0e85f51d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model, args, \n",
    "    train_dataset=tokenized_dataset['train'], \n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb4502a-65f5-4ca9-9b8c-57fce31ce84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9846' max='9846' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9846/9846 53:41, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.683675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.213300</td>\n",
       "      <td>2.074807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.942700</td>\n",
       "      <td>1.941350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.778000</td>\n",
       "      <td>1.887485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.641900</td>\n",
       "      <td>1.855742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.559600</td>\n",
       "      <td>1.847671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.523700</td>\n",
       "      <td>1.847974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9846, training_loss=1.813321922747023, metrics={'train_runtime': 3230.1163, 'train_samples_per_second': 18.289, 'train_steps_per_second': 3.048, 'total_flos': 4.487155818902323e+16, 'train_loss': 1.813321922747023, 'epoch': 6.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2203d1f-37f2-48e3-a970-53ed2b557641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Who is Leonardo Da Vinci? [/INST]\n",
      "\n",
      " Leonardo Da Vinci is a German-born German-born German-born German-French-Canadian-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American-American, and his mother, Alice. He is best known for his work as a psychologist, as well as his work as a psychotherapist and teacher. Da\n",
      "100 tokens in 0.52s: 191.91 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "ask_question(model, \"Who is Leonardo Da Vinci?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba61ede-1fae-4efa-9aaf-26b5bf3bed8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
