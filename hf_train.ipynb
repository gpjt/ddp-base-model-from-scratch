{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3478ecf2-c74c-4dca-8285-823ced0821d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"gpjt/test9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd7c73e-e507-4491-9309-ce358ad3de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_source = \"gpjt/openassistant-guanaco-llama2-format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78bb383-59b9-478d-b0d4-677a0296f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82a5b07-1d9d-4c4c-bf56-8f101639cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9ef044-cff8-4178-aab2-ee8c8c9bb9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"cuda\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4dc2a9-705e-48d8-b46e-ab86a1585a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "{question} [/INST]\n",
    "{response}\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "def ask_question(model, question):\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)\n",
    "    prompt = prompt_template.format(question=question, response=\"\")\n",
    "    tokens_in = len(tokenizer(prompt)[\"input_ids\"])\n",
    "    start = time.time()\n",
    "    result = pipe(prompt)\n",
    "    end = time.time()\n",
    "    generated_text = result[0]['generated_text']\n",
    "    tokens_out = len(tokenizer(generated_text)[\"input_ids\"])\n",
    "    print(generated_text)\n",
    "    tokens_generated = tokens_out - tokens_in\n",
    "    time_taken = end - start\n",
    "    tokens_per_second = tokens_generated / time_taken\n",
    "    print(f\"{tokens_generated} tokens in {time_taken:.2f}s: {tokens_per_second:.2f} tokens/s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d954f60-b994-4395-8097-8dde854c5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Who is Leonardo Da Vinci? [/INST]\n",
      "\n",
      ", what is he doing? [SYS]\n",
      "Sellers, like many other people, have been around for a long time, and this is not the only time to get to know him.\n",
      "Sellers, like many other people, have been around since they were teenagers. They have been around for a long time.\n",
      "They have been around for a long time, and they have been around for a long time.\n",
      "Sellers, like many other people, have been\n",
      "101 tokens in 0.75s: 135.26 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "ask_question(model, \"Who is Leonardo Da Vinci?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2194ba-1ba5-436e-b8fd-f82d415cac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"][:]\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5434c7-f9ed-4a21-9cbc-0889f3005fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "\n",
    "batch_size = 6\n",
    "args = TrainingArguments(\n",
    "    'outputs', \n",
    "    learning_rate=8e-5, \n",
    "    warmup_ratio=0.1, \n",
    "    lr_scheduler_type='cosine', \n",
    "    fp16=True,\n",
    "    eval_strategy=\"epoch\", \n",
    "    eval_on_start=True,\n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    num_train_epochs=6, \n",
    "    weight_decay=0.01, \n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b26e2c2-cdfd-404a-8644-cc0e85f51d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model, args, \n",
    "    train_dataset=tokenized_dataset['train'], \n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb4502a-65f5-4ca9-9b8c-57fce31ce84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16410' max='16410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16410/16410 1:29:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.683675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.263200</td>\n",
       "      <td>2.120376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.987100</td>\n",
       "      <td>1.957617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.812300</td>\n",
       "      <td>1.897972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.665800</td>\n",
       "      <td>1.860270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.553400</td>\n",
       "      <td>1.844390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.461100</td>\n",
       "      <td>1.839519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.374600</td>\n",
       "      <td>1.841558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.316300</td>\n",
       "      <td>1.843007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.288100</td>\n",
       "      <td>1.844653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.271800</td>\n",
       "      <td>1.846066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16410, training_loss=1.620934098991659, metrics={'train_runtime': 5391.0204, 'train_samples_per_second': 18.264, 'train_steps_per_second': 3.044, 'total_flos': 7.478593031503872e+16, 'train_loss': 1.620934098991659, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2203d1f-37f2-48e3-a970-53ed2b557641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Who is Leonardo Da Vinci? [/INST]\n",
      "\n",
      " Leonardo da Vinci is a 19-year-old Italian American man whose work has been recognized internationally for his contributions to the field of art and design. He was recognized for his contributions to the fields of art, design, and communication, and his work has made significant contributions to the fields of art, design, and communication.\n",
      "\n",
      " Da Vinci is known for his work in both commercial and non-profit work. He is known for his emphasis on artistic expression and his use of materials,\n",
      "99 tokens in 0.52s: 190.29 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "ask_question(model, \"Who is Leonardo Da Vinci?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba61ede-1fae-4efa-9aaf-26b5bf3bed8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
